# -*- coding: utf-8 -*-
"""EDA y preprocesamiento

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uUIxxI74kswjce--MUszAPkvd9dvmxf2

# Selecciona un conjunto de datos relacionado a algún tema o problemática de tu interés
(Se recomienda utilizar Kaggle para la búsqueda del conjunto de datos. El conjunto de datos deberá poder utilizarse para resolver algún problema de clasificación o de regresión.)

## En un notebook de Jupyter:

### 1.   Carga el conjunto de datos y descríbelo de forma breve.
### 2.    Asegúrate de incluir el enlace a la fuente.  https://www.kaggle.com/datasets/whenamancodes/predict-diabities
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler, OneHotEncoder, PowerTransformer
from sklearn.compose import ColumnTransformer

df = pd.read_csv('diabetes.csv')
df

"""## 3.  Describe el problema a resolver:
D = A partir de un dataset de 768 casos, buscamos predecir el diagnóstico de diabetes mediante machine learning. Los datos se distribuyeron en conjuntos de entrenamiento y validación; esta metodología nos permite entrenar el modelo de forma robusta y, posteriormente, poner a prueba su eficacia para alcanzar los mejores resultados posibles.

###4.   Realiza el EDA apropiado para tu conjunto de datos. Como mínimo:
      *   Identifica las columnas del conjunto de datos, así como el tipo de datos

      *   Determina cuáles columnas utilizarás para este problema
      *   Examina y visualiza la distribución de cada columna relevante
      *   Analiza la distribución de valores nulos o faltantes en cada columna relevante
      *   Describe los hallazgos principales
"""

df.info()

df.describe().T

"""*   Pregnancies (Embarazos): Número de veces que la paciente ha estado embarazada.

*   Glucose (Glucosa): Concentración de glucosa en plasma a las 2 horas de una prueba de tolerancia oral a la glucosa. Es uno de los predictores más fuertes.

*   BloodPressure (Presión arterial): Presión arterial diastólica (mm Hg).

*   SkinThickness (Grosor de la piel): Grosor del pliegue cutáneo del tríceps (mm). Se usa para estimar la grasa corporal.

*   Insulin (Insulina): Insulina sérica a las 2 horas (mu U/ml).

*   BMI (Índice de Masa Corporal): Peso en kg dividido por el cuadrado de la altura en metros.

*   DiabetesPedigreeFunction: Una función que puntúa la probabilidad de diabetes basándose en los antecedentes familiares. Cuanto más alto el número, más carga genética detectada.

*   Age (Edad): Edad en años.

*   Outcome (Resultado): La variable objetivo (clase). 0 significa que no tiene diabetes, 1 significa que sí tiene.

D = Se considera que todas las columnas del dataset son necesarias para la predicción de la enfermedad. No obstante, se detectó la presencia de valores nulos disfrazados de ceros en columnas críticas como 'Insulin', 'BloodPressure', 'BMI' y 'SkinThickness'. Este hallazgo requiere una intervención técnica previa al entrenamiento, ya que dichos valores no reflejan la realidad biológica de los pacientes y carecen de sentido clínico. Por consiguiente, la estrategia de limpieza consistió en identificar estos registros erróneos y sustituirlos por la mediana de cada columna, garantizando que el modelo procese información coherente, de calidad y libre de distorsiones estadísticas
"""

cols_con_ceros = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']

#Reemplazar los 0 por NaN para que pandas los identifique como faltantes
df[cols_con_ceros] = df[cols_con_ceros].replace(0, np.nan)

#Imputar (llenar) los valores faltantes con la mediana de cada columna
for col in cols_con_ceros:
    df[col] = df[col].fillna(df[col].median())

#Verificar que ya no hay nulos (ni ceros donde no debe)
print(df.isnull().sum())

numerical_cols = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness',
                  'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']

# 2. Ajustamos el subplots a 4 filas y 2 columnas (4x2 = 8 espacios para tus 8 variables)
fig, axs = plt.subplots(4, 2, figsize=(12, 16))

for ax, col in zip(axs.ravel(), numerical_cols):
    sns.histplot(df[col], kde=True, ax=ax, color="skyblue")
    ax.set_title(f'Distribución de {col}')
    ax.set_xlabel('') # Limpia el eje X para que sea más legible

fig.tight_layout()
plt.show()

"""D = Observamos que casi todas las variables tienen una buena distribución de datos. No obstante, SkinThickness y Pregnancies muestran comportamientos distintos que podrían confundir al modelo. Para evitar que estas variables dominen o distorsionen las predicciones, es altamente recomendable aplicar una normalización. Al transformar estos datos a una escala estándar, el modelo puede interpretar su importancia de manera más equilibrada."""

fig = plt.figure(figsize=(6, 4))
sns.countplot(data=df, x='Outcome')
plt.title('Countplot of Outcome')
plt.tight_layout()

"""D = Se observa un desbalance en los datos, donde el número de personas sanas supera considerablemente al de personas con diabetes. Debido a este desequilibrio, es probable que el modelo se incline a favorecer las predicciones de la clase mayoritaria, limitando su capacidad para identificar correctamente a los pacientes con la enfermedad.

##5.   Define un pipeline de preprocesamiento:
####Describe cuáles transformaciones aplicarás a cada columna y justifica la elección

##6.   Crea la instancia del pipeline utilizando la librería de sklearn
"""

from sklearn.impute import SimpleImputer
# 1. Definimos los grupos de columnas según el tratamiento que necesitan
# Variables que suelen tener mucha asimetría (sesgo)
cols_skewed = ['Insulin', 'DiabetesPedigreeFunction', 'Pregnancies']

# Variables que son más simétricas
cols_normal = ['Glucose', 'BloodPressure', 'SkinThickness', 'BMI', 'Age']

# 2. Creamos el preprocesador
preprocessing_pipeline = make_pipeline(
    ColumnTransformer(
        transformers=[
            # Para variables sesgadas: Imputamos, transformamos para normalizar y escalamos
            ('num_skewed', make_pipeline(
                SimpleImputer(strategy='median'),
                PowerTransformer(method='yeo-johnson'),
                StandardScaler()
            ), cols_skewed),

            # Para el resto: Solo imputamos y escalamos
            ('num_std', make_pipeline(
                SimpleImputer(strategy='median'),
                StandardScaler()
            ), cols_normal),
        ],
        remainder='drop'
    ))

preprocessing_pipeline

"""7.  Particiona el conjunto de datos en conjuntos de entrenamiento y de prueba"""

# 1. Separamos las características (X) de la etiqueta objetivo (y)
x = df.drop('Outcome', axis=1)
y = df['Outcome']

# 2. Dividimos el dataset
# test_size=0.2 significa 20% para prueba y 80% para entrenamiento
# random_state=42 asegura que siempre obtengas la misma división al ejecutarlo
# stratify=y mantiene la proporción de clases original
x_train, x_test, y_train, y_test = train_test_split(
    x, y, test_size=0.2, random_state=42, stratify=y
)

print(f"Registros para entrenamiento: {len(x_train)}")
print(f"Registros para evaluación: {len(x_test)}")

from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay

# 1. Creamos el Pipeline Completo (Preprocesamiento + Modelo)

classification_model = make_pipeline(
    preprocessing_pipeline,
    LogisticRegression(class_weight='balanced')
)

classification_model

classification_model.fit(x_train, y_train)

y_test_pred = classification_model.predict(x_test)
y_test_pred

# 1. Creamos un nuevo DataFrame solo para la comparación y no alterar x_test original
df_comparacion = x_test.copy()

# 2. Agregamos las etiquetas reales y las predicciones
df_comparacion['Real'] = y_test.values
df_comparacion['Prediccion'] = y_test_pred # La variable que guardó el resultado del modelo

# 3. Agregamos una columna que nos diga si acertó o no
df_comparacion['Acierto'] = df_comparacion['Real'] == df_comparacion['Prediccion']

# 4. Mostramos los casos donde el modelo se equivocó (Errores)
errores = df_comparacion[df_comparacion['Acierto'] == False]
print(f"Total de errores: {len(errores)}")
errores.head()

"""D = Si bien el modelo falló en los cuatro casos específicos de la tabla, estos forman parte de los 42 errores totales identificados. Para entender por qué ocurre esto, evaluaremos las métricas de clasificación, lo que nos permitirá apreciar de forma más clara cómo está operando el modelo en realidad.

### 8. Evaluar el rendimiento del modelo

Para entender mejor por qué el modelo "no está logrando predecir" como esperas, vamos a evaluar su rendimiento utilizando métricas comunes de clasificación.
"""

print('Classification Report:')
print(classification_report(y_test, y_test_pred))

# Matriz de Confusión
cm = confusion_matrix(y_test, y_test_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Sano', 'Diabetes'])
disp.plot(cmap='Blues')
plt.title('Matriz de Confusión (Modelo Balanceado)')
plt.show()

"""D = Al final se obtuvo los siguientes resultados: precision de 60 y recall de 69
* De 100 personas sanas, el modelo identificó correctamente a 75. Sin embargo, a 25 personas sanas les dijo que tenían diabetes (Falsos Positivos).

* De 54 personas enfermas, el modelo detectó a 37. Pero ojo, 17 personas con diabetes fueron clasificadas como sanas (Falsos Negativos).
"""
